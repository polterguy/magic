
// Asks OpenAI a question with the specified type, and returns the answer to caller.
.arguments
   prompt:string
   type:string
   references:bool
   chat:bool
   recaptcha_response:string
   session:string
   user_id:string
.description:Asks OpenAI a question with the specified type, and returns the answer to caller
.type:public

/*
 * Forward invocation to chat file, since there are no real differences
 * between the two endpoints, since we're checking model type in chat file
 * and acting accordingly.
 *
 * However, we still need to keep this file for legacy reasons.
 */
add:x:+
   get-nodes:x:@.arguments/*
io.file.execute:/system/openai/chat.get.hl
return:x:-/*
